{
  "id": "2323ffcc-fbc6-4398-94cc-8852ca3bc856",
  "revision": 0,
  "last_node_id": 14,
  "last_link_id": 21,
  "nodes": [
    {
      "id": 1,
      "type": "CheckpointLoaderSimple",
      "pos": [-200, 200],
      "size": [315, 105],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [1]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [2, 3]
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [4, 5]
        }
      ],
      "title": "1 | Load Checkpoint",
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": ["cyberrealisticXL_v70_fp32.safetensors"],
      "color": "#369"
    },
    {
      "id": 2,
      "type": "LoadImage",
      "pos": [-200, 400],
      "size": [315, 314],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [6, 7, 8]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "title": "2 | Load Reference Face",
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": ["example.png", "image"],
      "color": "#666"
    },
    {
      "id": 3,
      "type": "IPAdapterUnifiedLoaderFaceID",
      "pos": [-200, 0],
      "size": [315, 78],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 1
        }
      ],
      "outputs": [
        {
          "name": "model",
          "type": "MODEL",
          "links": [9]
        },
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "links": [10]
        }
      ],
      "title": "3 | IPAdapter Unified Loader FaceID",
      "properties": {
        "Node name for S&R": "IPAdapterUnifiedLoaderFaceID"
      },
      "widgets_values": ["FACEID PLUS V2", 1.0, "CoreML"],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 4,
      "type": "CLIPTextEncode",
      "pos": [150, 200],
      "size": [400, 200],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [11]
        }
      ],
      "title": "4 | Positive Prompt",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": ["photorealistic portrait, highly detailed skin texture with visible pores, natural skin imperfections, realistic skin detail, sharp focus, professional photography, lifelike skin"],
      "color": "#232"
    },
    {
      "id": 5,
      "type": "CLIPTextEncode",
      "pos": [150, 420],
      "size": [400, 200],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 3
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [12]
        }
      ],
      "title": "5 | Negative Prompt",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": ["blurry, low quality, cartoon, painting, illustration, plastic skin, smooth skin, airbrushed skin, over-processed skin, porcelain skin, waxy skin, bad anatomy, artifacts, soft focus"],
      "color": "#339"
    },
    {
      "id": 6,
      "type": "IPAdapterFaceID",
      "pos": [150, 0],
      "size": [315, 258],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 9
        },
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 10
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 6
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [13]
        }
      ],
      "title": "6 | IPAdapter FaceID",
      "properties": {
        "Node name for S&R": "IPAdapterFaceID"
      },
      "widgets_values": [0.6, 0.8, "linear", "concat", 0.0, 1.0],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 7,
      "type": "ControlNetLoader",
      "pos": [600, 0],
      "size": [315, 58],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CONTROL_NET",
          "type": "CONTROL_NET",
          "links": [14]
        }
      ],
      "title": "7 | Load ControlNet Tile",
      "properties": {
        "Node name for S&R": "ControlNetLoader"
      },
      "widgets_values": ["SDXL/TTPLANET_Controlnet_Tile_realistic_v2_fp16.safetensors"],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 8,
      "type": "ControlNetApplyAdvanced",
      "pos": [600, 80],
      "size": [315, 186],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 11
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 12
        },
        {
          "name": "control_net",
          "type": "CONTROL_NET",
          "link": 14
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "links": [15]
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "links": [16]
        }
      ],
      "title": "8 | Apply ControlNet Tile",
      "properties": {
        "Node name for S&R": "ControlNetApplyAdvanced"
      },
      "widgets_values": [0.45, 0.0, 1.0],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 9,
      "type": "VAEEncodeTiled",
      "pos": [950, 0],
      "size": [315, 78],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 8
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 4
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [17]
        }
      ],
      "title": "9 | VAE Encode Tiled",
      "properties": {
        "Node name for S&R": "VAEEncodeTiled"
      },
      "widgets_values": [512],
      "color": "#393"
    },
    {
      "id": 10,
      "type": "LatentUpscaleBy",
      "pos": [950, 100],
      "size": [315, 82],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [18]
        }
      ],
      "title": "10 | Latent Upscale 4x",
      "properties": {
        "Node name for S&R": "LatentUpscaleBy"
      },
      "widgets_values": ["nearest-exact", 4.0],
      "color": "#393"
    },
    {
      "id": 11,
      "type": "KSampler",
      "pos": [950, 200],
      "size": [315, 262],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 13
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 15
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 16
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 18
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [19]
        }
      ],
      "title": "11 | KSampler",
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [1234, "fixed", 30, 6.5, "dpmpp_2m_sde", "karras", 0.6],
      "color": "#393"
    },
    {
      "id": 12,
      "type": "VAEDecodeTiled",
      "pos": [950, 480],
      "size": [315, 78],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 19
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [20]
        }
      ],
      "title": "12 | VAE Decode Tiled",
      "properties": {
        "Node name for S&R": "VAEDecodeTiled"
      },
      "widgets_values": [512],
      "color": "#393"
    },
    {
      "id": 13,
      "type": "SaveImage",
      "pos": [1300, 0],
      "size": [600, 700],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 20
        }
      ],
      "outputs": [],
      "title": "13 | Save Image",
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": ["IPAdapter_FaceID_CoreML_4x"],
      "color": "#666"
    },
    {
      "id": 14,
      "type": "Note",
      "pos": [600, 300],
      "size": [600, 500],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "OPTIMIZED FOR FLUX→SDXL UPSCALING",
      "properties": {},
      "widgets_values": [
        "**IPAdapter FaceID + ControlNet Tile** - **FLUX→SDXL DETAIL GENERATION**\n\nThis workflow generates skin detail that Flux models don't create, using SDXL img2img upscaling.\n\n**CRITICAL: CoreML DOES NOT ACCELERATE on Mac (2+ hours processing)**\nCoreML falls back to CPU just like PuLID. For Mac users, use Multi-ControlNet_Latent (~30 seconds) instead.\n\n**IPAdapter FaceID Settings (Node 6):**\nwidgets_values: [0.6, 0.8, \"linear\", \"concat\", 0.0, 1.0]\n\n• weight: 0.6 (LOWER than default - prevents over-enhancement of facial features)\n  - Too high (1.0+) = distorted nose/mouth, unwanted hair transfer\n  - 0.6 = subtle face transfer, natural features\n• weight_faceidv2: 0.8 (LOWER than default - prevents feature distortion)\n  - Too high (2.0) = over-enhanced nose/mouth, sharp unwanted details\n  - 0.8 = balanced facial structure preservation\n• weight_type: \"linear\" | combine_embeds: \"concat\" | start_at: 0.0 | end_at: 1.0\n\n**FLUX→SDXL Critical Parameters:**\n\n1. **ControlNet Tile strength: 0.45** (MUCH LOWER than SDXL→SDXL)\n   - For SDXL→SDXL: use 0.7 (preserve existing detail)\n   - For Flux→SDXL: use 0.45 (allow SDXL to CREATE detail)\n   - Too high (0.7) = ringing artifacts, sharp edges, blocks detail generation\n   - 0.45 = structural guidance without constraining skin detail creation\n\n2. **Denoise: 0.6** (HIGHER than SDXL→SDXL)\n   - For SDXL→SDXL: use 0.42 (preserves existing skin detail)\n   - For Flux→SDXL: use 0.6+ (generates NEW skin detail)\n   - Flux images lack skin texture - need high denoise to force SDXL to create it\n   - 0.6 = strong enough to generate detail without excessive hallucinations\n\n3. **CFG: 6.5** (higher for detail generation)\n   - Stronger prompt adherence ensures skin detail follows \"natural skin texture\" prompt\n   - Helps SDXL generate realistic pores, texture, imperfections\n\n4. **Steps: 30** | **Sampler: dpmpp_2m_sde** (SDE essential for sharp detail) | **Scheduler: karras**\n\n5. **VAE tile size: 512px** (memory efficient, prevents tensor errors)\n\n**Why These Settings for Flux→SDXL:**\n- Flux generates smooth, detail-free skin (AI-perfect appearance)\n- SDXL excels at skin texture, pores, natural detail\n- Lower ControlNet = freedom to add detail Flux never had\n- Higher denoise = forces re-generation rather than preservation\n- Lower face weights = prevents feature distortion during detail generation\n\n**Test Results:**\nweight=1.0, weight_faceidv2=2.0, ControlNet 0.7, denoise 0.55:\n✗ Over-enhanced nose/mouth features\n✗ Unwanted hair transfer\n✗ Sharp edges with ringing artifacts  \n✗ Barely visible skin details (denoise too low for Flux input)\n\nweight=0.6, weight_faceidv2=0.8, ControlNet 0.45, denoise 0.6:\n✓ Natural facial features\n✓ Smooth edges without ringing\n✓ Visible skin texture and detail generation\n\n**Requirements:**\n• ComfyUI_IPAdapter_plus custom node\n• Model: ip-adapter-faceid-plusv2_sdxl.bin\n• ControlNet: TTPLANET_Controlnet_Tile_realistic_v2_fp16.safetensors\n• InsightFace models (auto-download for face analysis)\n\n**Performance Reality on Mac M4 Max:**\n• **Actual:** 2+ hours (CoreML falls back to CPU)\n• **Expected if CoreML worked:** 2-5 minutes (it doesn't)\n• **Recommended alternative:** Multi-ControlNet_Latent workflow (~30 seconds)\n\n**For Mac Users:**\nThis workflow is NOT viable on Mac due to 2+ hour processing time. CoreML execution provider does NOT accelerate InsightFace models. Use Multi-ControlNet_4x_Upscale_with_PuLID_SDXL.json instead for acceptable performance."
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [1, 1, 0, 3, 0, "MODEL"],
    [2, 1, 1, 4, 0, "CLIP"],
    [3, 1, 1, 5, 0, "CLIP"],
    [4, 1, 2, 9, 1, "VAE"],
    [5, 1, 2, 12, 1, "VAE"],
    [6, 2, 0, 6, 2, "IMAGE"],
    [7, 2, 0, 8, 3, "IMAGE"],
    [8, 2, 0, 9, 0, "IMAGE"],
    [9, 3, 0, 6, 0, "MODEL"],
    [10, 3, 1, 6, 1, "IPADAPTER"],
    [11, 4, 0, 8, 0, "CONDITIONING"],
    [12, 5, 0, 8, 1, "CONDITIONING"],
    [13, 6, 0, 11, 0, "MODEL"],
    [14, 7, 0, 8, 2, "CONTROL_NET"],
    [15, 8, 0, 11, 1, "CONDITIONING"],
    [16, 8, 1, 11, 2, "CONDITIONING"],
    [17, 9, 0, 10, 0, "LATENT"],
    [18, 10, 0, 11, 3, "LATENT"],
    [19, 11, 0, 12, 0, "LATENT"],
    [20, 12, 0, 13, 0, "IMAGE"]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}
