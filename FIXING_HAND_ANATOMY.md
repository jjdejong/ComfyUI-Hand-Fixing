# Fixing Hand Anatomy Issues: Missing/Extra Fingers & Wrong Thumb Position
**Focused guide for fixing structural hand problems: wrong finger count and thumb anatomy**

---

## DEPRECATED - See Updated Approach

**This guide describes the MeshGraphormer approach which has been deprecated.**

**Problem found:** MeshGraphormer creates tight "glove-like" masks that follow the exact contours of malformed hands, preventing proper regeneration of correct anatomy.

**Current recommended approach:** FaceDetailer with BBOX-only mode (rectangular bounding boxes)
- See `workflows/README.md` for the current recommended workflow
- See `workflows/Generate with Hand Fix and Upscale.json` for implementation
- BBOX mode gives the model freedom to regenerate correct hand anatomy
- Tested optimal parameters: denoise 0.5, cfg 6.0, bbox_crop_factor 2.5

**This document is kept for reference only.** The MeshGraphormer workflows mentioned below have been removed from the repository.

---

## Why Simple Inpainting Doesn't Work

When hands have:
- 6+ fingers or less than 5 fingers
- Thumbs that look like regular fingers
- Thumbs in the wrong position
- Fused fingers that need to be separated
**Simple detailers (FaceDetailer, BMAB) will fail** because they:
- Only re-render what they see
- Don't understand hand anatomy
- Can't add/remove fingers reliably
- Don't know where thumbs should be
**You need anatomical guidance** - a 3D hand pose that tells the AI "this is what a correct hand looks like."

---

## Solution: MeshGraphormer + ControlNet

### What This Does

```
Your Broken Hand Image
 ↓
MeshGraphormer analyzes it
 ↓
Creates 3D hand skeleton (ALWAYS 5 fingers, correct thumb position)
 ↓
Converts to depth map (shows proper hand structure)
 ↓
ControlNet uses this as a guide
 ↓
Regenerates hand with correct anatomy
```
**Key advantage**: MeshGraphormer creates an anatomically correct hand skeleton regardless of what's in the input image. It's not trying to "fix" what it sees - it's **replacing** the hand structure with a correct one.

---

## Complete Setup Guide

### Prerequisites
- ComfyUI installed
- 8GB+ VRAM (10GB+ recommended)
- Your existing FaceDetailer setup (for faces)

### Step 1: Install ControlNet Auxiliary Preprocessors (includes MeshGraphormer)
**MeshGraphormer is part of the ControlNet Auxiliary Preprocessors package.**
**Option A: Using ComfyUI Manager (Recommended)**
```
1. Open ComfyUI
2. Click "Manager" button
3. Click "Install Custom Nodes"
4. Search for "ControlNet Auxiliary Preprocessors"
5. Click "Install" on "ComfyUI's ControlNet Auxiliary Preprocessors"
6. Restart ComfyUI
```
**Option B: Manual Installation**
```bash
cd ComfyUI/custom_nodes/
git clone https://github.com/Fannovel16/comfyui_controlnet_aux.git
cd comfyui_controlnet_aux
pip install -r requirements.txt

# Restart ComfyUI
```
**Option C: Manual Download (No Git)**
```
1. Visit: https://github.com/Fannovel16/comfyui_controlnet_aux
2. Click "Code" → "Download ZIP"
3. Extract to: ComfyUI/custom_nodes/comfyui_controlnet_aux/
4. Open terminal in that folder
5. Run: pip install -r requirements.txt
6. Restart ComfyUI
```

The MeshGraphormer model will automatically download (~200MB) on first use.

### Step 2: Install ControlNet Depth Model
**For SD1.5 models:**
```bash
cd ComfyUI/models/controlnet/
wget https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth
```
**For SDXL models:**
```bash
cd ComfyUI/models/controlnet/
wget https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0/resolve/main/diffusers_xl_depth_full.safetensors
```

### Step 3: Get Hand Detection Model

You already have this if you use FaceDetailer:
```bash
cd ComfyUI/models/ultralytics/bbox/

# Should already have this file, or download:
wget https://huggingface.co/Bingsu/adetailer/resolve/main/hand_yolov8s.pt
```

---

## The Complete Workflow

### Overview

```
Load Image
 ↓
Detect Hands (YOLO) → Get hand bounding boxes
 ↓
Crop Hand Regions → Isolate each hand
 ↓
MeshGraphormer → Generate anatomically correct 3D hand pose
 ↓
Create Depth Map → Convert 3D pose to 2D depth guidance
 ↓
ControlNet + Inpainting → Regenerate hand guided by correct anatomy
 ↓
Composite Back → Blend fixed hand into original image
 ↓
Save Result
```

### Detailed Node Setup

Here's the exact workflow to implement:

```
┌─────────────────────────────────────────────────────────────────┐
│ PART 1: LOAD AND DETECT │
└─────────────────────────────────────────────────────────────────┘

[1] LoadImage
 └─ image: your_image.png

[2] UltralyticsDetectorProvider
 └─ model_name: "bbox/hand_yolov8s.pt"

[3] BBoxDetectorForEach (from Impact Pack)
 ├─ image: [1]
 ├─ bbox_detector: [2]
 ├─ threshold: 0.5
 ├─ dilation: 20
 └─ crop_factor: 1.5
 │
 └──> [Cropped Hand Images + Masks + Boxes]


┌─────────────────────────────────────────────────────────────────┐
│ PART 2: GENERATE CORRECT HAND ANATOMY │
└─────────────────────────────────────────────────────────────────┘

[4] MeshGraphormer Hand Refiner (from ControlNet Auxiliary Preprocessors)
 # Also known as: MeshGraphormer-DepthMapPreprocessor
 ├─ image: [3] cropped hands
 └─ Output: depth map showing anatomically correct hand structure
 │
 └──> [Hand Depth Map - anatomically correct with 5 fingers]

[5] ImageResize
 ├─ image: [4] depth map
 ├─ width: match original crop size
 ├─ height: match original crop size
 └─ interpolation: "lanczos"


┌─────────────────────────────────────────────────────────────────┐
│ PART 3: SETUP CONTROLNET AND CONDITIONING │
└─────────────────────────────────────────────────────────────────┘

[6] Load Checkpoint
 └─ ckpt_name: "your_model.safetensors"

[7] ControlNetLoader
 └─ control_net_name: "control_v11f1p_sd15_depth.pth" # or SDXL version

[8] CLIPTextEncode (Positive)
 ├─ clip: [6]
 └─ text: "detailed human hand, five fingers, proper thumb placement,
 natural hand anatomy, realistic skin texture, well-defined
 knuckles, natural hand pose, photorealistic"

[9] CLIPTextEncode (Negative)
 ├─ clip: [6]
 └─ text: "deformed hand, extra fingers, missing fingers, 6 fingers,
 4 fingers, 3 fingers, fused fingers, mutated hand, bad anatomy,
 extra limbs, poorly drawn hand, thumb like finger, wrong thumb
 position, disconnected fingers, floating digits"

[10] ControlNetApplyAdvanced
 ├─ positive: [8]
 ├─ negative: [9]
 ├─ control_net: [7]
 ├─ image: [5] (the depth map from MeshGraphormer)
 ├─ strength: 0.9 # High strength - follow anatomy closely
 ├─ start_percent: 0.0 # Apply from beginning
 └─ end_percent: 0.85 # Apply through most of sampling
 │
 └──> [Conditioned Positive/Negative with anatomy guidance]


┌─────────────────────────────────────────────────────────────────┐
│ PART 4: INPAINT WITH ANATOMICAL GUIDANCE │
└─────────────────────────────────────────────────────────────────┘

[11] VAEEncode
 ├─ pixels: [3] (cropped hand)
 ├─ vae: [6]
 └─ mask: [3] (hand mask)
 └──> [Latent]

[12] VAEEncodeForInpaint (alternative to [11])
 ├─ pixels: [3]
 ├─ vae: [6]
 ├─ mask: [3]
 └─ grow_mask_by: 6
 └──> [Inpaint Latent]

[13] KSampler (for inpainting)
 ├─ model: [6]
 ├─ seed: [random or fixed]
 ├─ steps: 35-45 # More steps for anatomical correction
 ├─ cfg: 8.0-9.0 # Higher CFG to follow guidance strictly
 ├─ sampler_name: "dpmpp_2m" or "euler_a"
 ├─ scheduler: "karras"
 ├─ positive: [10] (with ControlNet)
 ├─ negative: [10]
 ├─ latent_image: [12]
 └─ denoise: 0.85-0.95 # High denoise for structural changes
 │
 └──> [Fixed Hand Latent]

[14] VAEDecode
 ├─ samples: [13]
 └─ vae: [6]
 └──> [Fixed Hand Image]


┌─────────────────────────────────────────────────────────────────┐
│ PART 5: COMPOSITE BACK INTO ORIGINAL IMAGE │
└─────────────────────────────────────────────────────────────────┘

[15] ImageCompositeMasked
 ├─ destination: [1] (original image)
 ├─ source: [14] (fixed hand)
 ├─ mask: [3] (hand mask, slightly feathered)
 └─ x, y: [3] (position from bbox)
 └──> [Final Image with Fixed Hand]

[16] SaveImage
 └─ images: [15]
```

---

## Critical Settings for Your Use Case

### MeshGraphormer Settings
- **output_type**: `"depth"` (creates depth map for ControlNet)
- **threshold**: 0.1-0.2 (hand detection sensitivity)

### ControlNet Settings (Most Important!)
- **strength**: **0.85-0.95** (very high - you want to force correct anatomy)
- **start_percent**: **0.0** (apply from the very beginning)
- **end_percent**: **0.85** (apply through most of sampling, let last 15% refine details)

Why high strength? Because you want to **override** the wrong anatomy, not just "guide" it.

### Sampling Settings
- **steps**: **35-45** (more steps = better anatomical correction)
- **cfg**: **8.0-9.0** (higher than normal - makes it follow the prompts and ControlNet more strictly)
- **denoise**: **0.85-0.95** (high - you're making major structural changes)
- **sampler**: `dpmpp_2m` or `euler_a` (both work well)
- **scheduler**: `karras` (smoother, better for controlled generation)

### Prompts (Critical!)
**Positive prompt template:**
```
"masterpiece, best quality, detailed human hand, five fingers, one thumb and four fingers,
proper thumb placement, thumb at correct angle, natural hand anatomy, realistic proportions,
well-defined knuckles, natural skin texture, photorealistic hand, correct finger count"
```
**Negative prompt template:**
```
"deformed hand, extra fingers, missing fingers, 6 fingers, 4 fingers, 3 fingers, 7 fingers,
fused fingers, merged digits, mutated hand, bad hand anatomy, extra limbs, poorly drawn hand,
malformed hand, thumb like finger, thumb in wrong position, extra thumbs, missing thumb,
disconnected fingers, floating digits, wrong proportions, bad anatomy, disfigured"
```
**Key phrases to include:**
- Positive: "five fingers", "one thumb and four fingers", "proper thumb placement"
- Negative: Every wrong finger count (3, 4, 6, 7 fingers), "thumb like finger"

---

## Simplified Workflow for Beginners

If the full workflow is too complex, here's a simpler version using FaceDetailer as the base:

```
[1] Load Image

[2] FaceDetailer (for faces first)
 └─ [standard face settings]

[3] UltralyticsDetectorProvider (hands)
 └─ model: hand_yolov8s.pt

[4] DetailerForEachDebug (from Impact Pack)
 ├─ image: [2]
 ├─ detector: [3]
 ├─ [Use sub-workflow below]


┌─── SUB-WORKFLOW inside DetailerForEach ────┐
│ │
│ [Cropped Hand] ──> MeshGraphormer ──> Depth│
│ │ │
│ ControlNet Loader ───────────────────┘ │
│ │ │
│ └──> Apply to Positive Prompt │
│ │ │
│ KSampler │
│ │ │
│ VAE Decode ────> [Out] │
│ │
└─────────────────────────────────────────────┘

[5] Save Image
```

This is easier because `DetailerForEach` handles the cropping, positioning, and compositing automatically.

---

## Testing Your Setup

### Step 1: Test with a Simple Case

Start with an image where:
- Hand is clearly visible
- Not too small (hand should be at least 200x200 pixels)
- Only one hand with clear issues

### Step 2: Verify MeshGraphormer Output

Add a "Save Image" node after the MeshGraphormer depth output. You should see:
- A depth map showing a hand silhouette
- 5 distinct fingers
- Thumb at proper angle (not parallel to fingers)
- Clear depth gradation
**If the depth map looks wrong**, MeshGraphormer couldn't detect the hand structure. Try:
- Increasing the crop factor (give more context)
- Adjusting hand detection threshold
- Ensuring the hand is large enough in the image

### Step 3: Check ControlNet is Working

After the first generation, check if:
- Finger count is now correct
- Thumb is in proper position
- Hand anatomy looks natural
**If ControlNet isn't being followed:**
- Increase strength to 0.95
- Increase CFG to 9.0-9.5
- Add more emphasis in prompts: "(five fingers:1.3)", "(proper thumb:1.2)"

### Step 4: Iterate

- Try different seeds (some will work better than others)
- Adjust denoise: higher = more change, lower = preserve more
- Tweak end_percent: 0.8-0.9 range

---

## Comparison: Before and After Workflow

### Your Current Situation
```
Image with wrong hands
 ↓
[Regular detailer - just re-renders what it sees]
 ↓
Still wrong hands (or slightly better but not fixed)
```

### With MeshGraphormer
```
Image with 6 fingers
 ↓
MeshGraphormer: "Here's what a correct 5-finger hand looks like"
 ↓
ControlNet: "Generate a hand matching this correct structure"
 ↓
Image with 5 fingers in correct positions
```

---

## Expected Success Rates

Based on community reports and my analysis:

| Issue | Success Rate | Notes |
|-------|--------------|-------|
| Extra finger (6 fingers) | 85-90% | High success if hand is clear |
| Missing finger (4 fingers) | 80-85% | May need multiple attempts |
| Thumb looks like finger | 90-95% | MeshGraphormer excels at this |
| Fused fingers | 70-80% | Harder, may need manual touch-up |
| Multiple issues | 60-75% | May need 2-3 iterations |
| Tiny hands (<100px) | 40-50% | MeshGraphormer struggles with small hands |
**Success factors:**
- Hand is clearly visible
- Good lighting in original
- Hand is large enough (200px+)
- Not heavily occluded
- Hand too small
- Heavily blurred
- Multiple overlapping hands

---

## Alternative: Flux Fill + MeshGraphormer (Experimental)

For even better results, you can combine Flux Fill (better inpainting) with MeshGraphormer (anatomical guidance):

```
Hand Detection
 ↓
MeshGraphormer ──> Depth Map
 ↓
FluxFill with ControlNet Depth
 ↓
Fixed Hand
```

This is experimental but some users report 95%+ success rates. The setup is more complex (see HAND_FIXING_GUIDE.md Method 3 + 4 combined).

---

## Troubleshooting Specific Issues

### Issue: Still generating 6 fingers
**Diagnosis:** ControlNet strength too low or CFG too low
**Fix:**
```
1. Increase ControlNet strength: 0.95
2. Increase CFG: 9.0-9.5
3. Add to negative prompt: "(6 fingers:1.5), (extra finger:1.4), (six digits:1.3)"
4. Add to positive prompt: "(exactly five fingers:1.3)"
5. Increase denoise to 0.95
6. Try different seed
```

### Issue: Thumb still looks like a regular finger
**Diagnosis:** MeshGraphormer depth map not showing thumb angle correctly, or ControlNet not being followed
**Fix:**
```
1. Check MeshGraphormer output - save the depth map and verify thumb angle
2. If depth map is wrong: increase crop_factor to 2.0-2.5 (more context)
3. If depth map is correct but not followed:
 - Increase ControlNet strength to 0.95
 - Add negative: "(thumb parallel to fingers:1.5), (five identical fingers:1.3)"
 - Add positive: "(thumb at 90 degree angle:1.2), (opposable thumb:1.2)"
```

### Issue: Hand detection misses hands
**Diagnosis:** Hands too small or threshold too high
**Fix:**
```
1. Lower bbox_threshold to 0.3-0.4
2. Check image resolution - hands should be at least 150x150px
3. Try SAM (Segment Anything) instead of YOLO for detection
4. Manually create mask if needed
```

### Issue: Fixed hand looks artificial/CGI
**Diagnosis:** Too much change, denoise too high, or not enough context
**Fix:**
```
1. Lower denoise to 0.75-0.8
2. Increase crop_factor to 3.0-4.0 (more surrounding context)
3. Lower CFG to 7.5
4. Add to positive: "photorealistic, natural skin texture, realistic lighting"
5. Use a better base model (realistic checkpoint, not anime)
```

### Issue: Background around hand changes
**Diagnosis:** Mask too large or feathering incorrect
**Fix:**
```
1. Reduce mask dilation: 10-15 instead of 20
2. Add mask blur/feather: 5-10 pixels
3. Lower denoise to 0.7-0.8
4. Use "VAEEncodeForInpaint" with grow_mask_by: 4-6
```

### Issue: Out of memory
**Diagnosis:** MeshGraphormer + ControlNet + high resolution = memory intensive
**Fix:**
```
1. Reduce guide_size in detailer to 512 or 384
2. Enable "lowvram" mode in ComfyUI settings
3. Process one hand at a time
4. Reduce base image resolution before processing
5. Use fp16 models instead of fp32
```

---

## When to Use This vs. Other Methods

### Use MeshGraphormer When:
 Hand has wrong number of fingers (main use case)
 Thumb is positioned like a finger
 Fingers are in anatomically impossible positions
 You need structural correction, not just quality improvement
 You have 8GB+ VRAM
 You're willing to invest time in setup

### Don't Use MeshGraphormer When:
 Hand is just slightly blurry (use simple detailer)
 Anatomy is correct, just needs sharpening (use FaceDetailer + hand YOLO)
 Hand is very small in image (MeshGraphormer needs detail)
 You need fast processing (MeshGraphormer is slow: 60-90 seconds per hand)
 You have <8GB VRAM

---

## Quick Start Checklist

- [ ] Install ComfyUI-MeshGraphormer custom node
- [ ] Download ControlNet Depth model for your checkpoint type (SD1.5 or SDXL)
- [ ] Verify hand_yolov8s.pt is in models/ultralytics/bbox/
- [ ] Test MeshGraphormer on a simple hand crop - verify depth output
- [ ] Build basic workflow: detect → crop → MeshGraphormer → ControlNet → inpaint
- [ ] Test with one image with clear wrong finger count
- [ ] Adjust ControlNet strength (start at 0.9)
- [ ] Refine prompts with specific finger count emphasis
- [ ] Experiment with different seeds
- [ ] Save working configuration for future use

---

## Recommended Models
**For SD1.5:**
- Checkpoint: Realistic Vision, Deliberate, or similar photorealistic model
- ControlNet: control_v11f1p_sd15_depth.pth
- VAE: vae-ft-mse-840000-ema-pruned.safetensors
**For SDXL:**
- Checkpoint: RealVisXL, Juggernaut XL, or similar
- ControlNet: diffusers_xl_depth_full.safetensors
- VAE: sdxl_vae.safetensors (or built-in)
**Important:** Use photorealistic models, not anime/illustration models, for hand anatomy correction.

---

## Example Prompts That Work

### For fixing 6 fingers → 5 fingers:
```
Positive:
"masterpiece, best quality, realistic human hand, exactly five fingers,
detailed hand anatomy, one thumb four fingers, proper finger count,
natural proportions, photorealistic skin, well-defined knuckles"

Negative:
"(6 fingers:1.5), (extra finger:1.4), (seven fingers:1.3), (six digits:1.3),
deformed hand, bad anatomy, extra digit, fewer digits, fused fingers,
mutated hand, disfigured"
```

### For fixing thumb that looks like finger:
```
Positive:
"detailed hand, proper thumb anatomy, (opposable thumb:1.2), thumb at natural angle,
correct thumb position, thumb distinct from fingers, realistic hand structure,
five digits with proper thumb placement"

Negative:
"(thumb parallel to fingers:1.5), (thumb like finger:1.4), (five identical fingers:1.3),
wrong thumb position, thumb in line with fingers, incorrect thumb angle, bad hand anatomy"
```

### For fixing missing finger:
```
Positive:
"complete hand, (five fingers:1.3), (full set of fingers:1.2), all fingers visible,
detailed hand anatomy, one thumb and four fingers, no missing digits,
complete hand structure"

Negative:
"(missing fingers:1.5), (4 fingers:1.4), (three fingers:1.3), (incomplete hand:1.3),
fewer digits, cut off fingers, partial hand, amputated"
```

---

## Final Tips

1. **Start with clear test images**: Don't use your most important image first. Test with clear examples.

2. **Save your depth maps**: Always save the MeshGraphormer output to verify it's detecting correct anatomy.

3. **Use fixed seeds when iterating**: Once you find settings that work, use a fixed seed and only adjust one parameter at a time.

4. **Batch process carefully**: Don't batch process until you've verified settings work on individual images.

5. **Keep original**: Always keep original images. Sometimes the "fix" makes things worse.

6. **Iterate if needed**: If first attempt doesn't work, try:
 - Different seed
 - Adjust denoise ±0.1
 - Adjust ControlNet strength ±0.05
 - Modify prompts

7. **Combine with face detailing**: Process faces first (FaceDetailer), then hands (MeshGraphormer), for complete image enhancement.

8. **Consider manual touch-up**: For critical work, use the MeshGraphormer result as 95% solution, then manual paint touch-up for final 5%.

---

## Next Steps

1. **Install MeshGraphormer** - Start with the basic installation
2. **Test on one image** - Pick an image with clear 6-finger or wrong-thumb issue
3. **Verify depth output** - Make sure MeshGraphormer generates correct depth
4. **Build basic workflow** - Start simple, add complexity later
5. **Iterate and refine** - Adjust settings based on results

Good luck fixing those hand anatomy issues! 

---

## Additional Resources

- **MeshGraphormer Paper**: https://arxiv.org/abs/2104.00506
- **MeshGraphormer Node**: https://github.com/ZHO-ZHO-ZHO/ComfyUI-MeshGraphormer
- **ControlNet Paper**: https://arxiv.org/abs/2302.05543
- **Community Examples**: Search "MeshGraphormer hand fix" on CivitAI and ComfyWorkflows

